#!/usr/bin/env python3
"""
Interactive guide for running comparison tests
"""

import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def display_main_menu():
    """Display the main comparison menu"""
    print("\nğŸ§ª BoD Analysis Comparison Guide")
    print("=" * 50)
    print("Choose a comparison test to run:")
    print()
    print("1. ğŸ”§ Test OpenAI Configuration")
    print("   - Verify OpenAI API key and basic functionality")
    print("   - Quick test with sample document")
    print()
    print("2. âš¡ Simple Comparison (OpenAI vs Ollama)")
    print("   - Quick performance comparison")
    print("   - Basic analysis metrics")
    print()
    print("3. ğŸ§ª Comprehensive Comparison")
    print("   - Detailed analysis quality comparison")
    print("   - Multiple metrics and sample outputs")
    print()
    print("4. ğŸ”´ Live Comparison Tool")
    print("   - Interactive tool with your own documents")
    print("   - Real-time provider selection")
    print()
    print("5. ğŸ“– View Comparison Guide")
    print("   - Tips for choosing the right provider")
    print("   - Performance vs cost considerations")
    print()
    print("0. Exit")

def run_openai_config_test():
    """Run OpenAI configuration test"""
    print("\nğŸ”§ Running OpenAI Configuration Test...")
    try:
        import subprocess
        result = subprocess.run([
            sys.executable, 
            str(project_root / 'tests' / 'comparison' / 'test_openai_config.py')
        ], capture_output=True, text=True)
        
        print(result.stdout)
        if result.stderr:
            print("Errors:", result.stderr)
        
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ Failed to run test: {e}")
        return False

def run_simple_comparison():
    """Run simple comparison test"""
    print("\nâš¡ Running Simple Comparison...")
    try:
        import subprocess
        result = subprocess.run([
            sys.executable, 
            str(project_root / 'tests' / 'comparison' / 'simple_comparison.py')
        ], capture_output=True, text=True)
        
        print(result.stdout)
        if result.stderr:
            print("Errors:", result.stderr)
        
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ Failed to run test: {e}")
        return False

def run_comprehensive_comparison():
    """Run comprehensive comparison test"""
    print("\nğŸ§ª Running Comprehensive Comparison...")
    try:
        import subprocess
        result = subprocess.run([
            sys.executable, 
            str(project_root / 'tests' / 'comparison' / 'test_openai_vs_ollama.py')
        ], capture_output=True, text=True)
        
        print(result.stdout)
        if result.stderr:
            print("Errors:", result.stderr)
        
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ Failed to run test: {e}")
        return False

def run_live_comparison():
    """Run live comparison tool"""
    print("\nğŸ”´ Starting Live Comparison Tool...")
    try:
        import subprocess
        result = subprocess.run([
            sys.executable, 
            str(project_root / 'tests' / 'comparison' / 'live_comparison.py')
        ])
        return True
    except Exception as e:
        print(f"âŒ Failed to run tool: {e}")
        return False

def show_comparison_guide():
    """Display comparison guide information"""
    print("\nğŸ“– BoD Analysis Provider Comparison Guide")
    print("=" * 60)
    
    print("\nğŸ¤– Provider Overview:")
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Provider    â”‚ Cost     â”‚ Speed   â”‚ Quality  â”‚ Best For    â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ Ollama      â”‚ FREE     â”‚ ~25s    â”‚ Very Goodâ”‚ Daily Use   â”‚")
    print("â”‚ OpenAI      â”‚ $0.01-05 â”‚ ~18s    â”‚ Excellentâ”‚ Critical    â”‚")
    print("â”‚ Mistral     â”‚ $0.01-03 â”‚ ~22s    â”‚ Good     â”‚ Cost-Aware  â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    
    print("\nğŸ’¡ Choosing the Right Provider:")
    print("   ğŸ†“ Ollama: Best for regular analysis, no ongoing costs")
    print("   ğŸš€ OpenAI: Best for complex documents requiring high accuracy")
    print("   ğŸ’° Mistral: Good balance of cost and quality")
    
    print("\nâš¡ Performance Considerations:")
    print("   â€¢ Document length affects processing time")
    print("   â€¢ Complex documents may benefit from premium providers")
    print("   â€¢ Ollama requires local installation but is completely free")
    print("   â€¢ Cloud providers need API keys and have usage costs")
    
    print("\nğŸ¯ Recommendation:")
    print("   1. Start with Ollama for daily board analysis tasks")
    print("   2. Use OpenAI for critical presentations or complex documents")
    print("   3. Consider Mistral as a cost-effective premium alternative")
    
    print("\nğŸ”§ Setup Requirements:")
    print("   â€¢ Ollama: Install from https://ollama.ai and run 'ollama pull llama3.2:3b'")
    print("   â€¢ OpenAI: Set OPENAI_API_KEY in your .env file")
    print("   â€¢ Mistral: Set MISTRAL_API_KEY in your .env file")
    
    # Read additional guide from docs if available
    guide_file = project_root / 'docs' / 'guides' / 'ui_comparison_guide.txt'
    if guide_file.exists():
        print(f"\nğŸ“„ Additional Information:")
        print(f"   See detailed guide: {guide_file}")
    
    input("\nPress Enter to continue...")

def main():
    """Main interactive guide"""
    print("ğŸš€ Welcome to the BoD Analysis Comparison Suite!")
    
    while True:
        try:
            display_main_menu()
            
            choice = input("\nSelect an option (0-5): ").strip()
            
            if choice == "0":
                print("\nğŸ‘‹ Thank you for using the comparison suite!")
                break
            elif choice == "1":
                run_openai_config_test()
            elif choice == "2":
                run_simple_comparison()
            elif choice == "3":
                run_comprehensive_comparison()
            elif choice == "4":
                run_live_comparison()
            elif choice == "5":
                show_comparison_guide()
            else:
                print("âŒ Invalid choice. Please select 0-5.")
            
            if choice in ["1", "2", "3"]:
                input("\nPress Enter to continue...")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Unexpected error: {e}")

if __name__ == "__main__":
    main()